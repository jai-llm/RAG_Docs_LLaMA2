{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1MHRwAXp6yYxtZgCLo1zf3dhd6eU2ZVGu",
      "authorship_tag": "ABX9TyOEkIdoKhZuFZhrIt4RMZij",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jai-llm/RAG_Docs_LLaMA2/blob/main/RAG_HastieBooks_chromaDB_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Colab Notebook\n",
        "@jai-llm\n",
        "\n",
        "14-Sep-2023\n",
        "\n",
        "This notebook does **R**etreival **A**ugmented **G**eneration to improve the results from the LLaMA2 model and reduce hallucinations.\n",
        "\n",
        "This notebook uses RAG to answers ML questions using the freely available ISLP and ESL textbooks by Hastie et al as context.\n",
        "\n",
        "These books can be downloaded from Prof. Hastie's webpage at:\n",
        "\n",
        "1. ISLP - https://hastie.su.domains/ISLP/ISLP_website.pdf\n",
        "2. ESL - https://hastie.su.domains/Papers/ESLII.pdf\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note**: Notebook needs at least a T4 GPU. Go to Edit -> Notebook Setting and select T4 GPU from the  text box. The Free Tier of Google Colab gives you access to a T4 GPU. Colab Notebook uses 7.6 GB of GPU RAM (15 GB of GPU RAM is available on a T4 GPU)."
      ],
      "metadata": {
        "id": "NDBmz-ZWS2mg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Packages"
      ],
      "metadata": {
        "id": "eWNquob_SvOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading in PDF Files\n",
        "!pip install -q -U pypdf\n",
        "# Setting Up Vector Store\n",
        "!pip install -q -U chromadb\n",
        "# Using Llama-7b-GPTQ LLM model in HuggingFace\n",
        "!pip install q -U torch auto-gptq transformers optimum\n",
        "# LangChain - Loading PDFs, Text Chunking, BGE Embeddings, Retrieval QA Chain\n",
        "!pip install -q -U langchain sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzTqNWh_co4e",
        "outputId": "12255255-6ab3-4727-d798-f5b2d26a1e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: q in /usr/local/lib/python3.10/dist-packages (2.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: auto-gptq in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: accelerate>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.23.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.14.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.23.5)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.3.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum) (15.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.19.0->auto-gptq) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers) (3.20.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum) (10.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Do Imports"
      ],
      "metadata": {
        "id": "EfO3hwYdezeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Import for loading PDFs from Google Drive.\n",
        "# Note: Not needed if GDrive is already mounted or we are using wget to get files from Web.\n",
        "from google.colab import drive\n",
        "\n",
        "# Imports to read PDF and setup Chroma Vector Store\n",
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "# Imports for LLM\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain import PromptTemplate  #, LLMChain\n",
        "\n",
        "# Imports for QA Retrieval Chain\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Import to Clenup LLM Output\n",
        "import textwrap"
      ],
      "metadata": {
        "id": "ZqZtOUSCfVAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ],
      "metadata": {
        "id": "0HWwitwgnPk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM Token Chunksize varies based on Context Window. LLaMA2 Context Window is 4096 tokens.\n",
        "# For QA want to pick larger chunk size with some overlap to get context.\n",
        "CHUNK_SIZE, CHUNK_OVERLAP = 1000, 200"
      ],
      "metadata": {
        "id": "92C4eGFNnO0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.0 Get Books From Hastie's Website\n",
        "\n",
        "**Note:** Do this Section Once to download and store files"
      ],
      "metadata": {
        "id": "oiVHaZNBPVdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOYgq3P87z2l",
        "outputId": "4bc00c5f-e423-4d0f-c836-72c4af930a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do this only once\n",
        "!mkdir -p 'hastie_pdfs'"
      ],
      "metadata": {
        "id": "1GCHkhmHRRv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This overwrites files in hastie_pdfs but does not need to be executed more than once\n",
        "!wget https://hastie.su.domains/ISLP/ISLP_website.pdf -O /hastie_pdfs/ISLP_website.pdf\n",
        "!wget https://hastie.su.domains/Papers/ESLII.pdf -O /hastie_pdfs/ESLII.pdf"
      ],
      "metadata": {
        "id": "yep9wcYDQyAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c874492-03f4-41ea-a558-f7dc357bc326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-15 00:07:12--  https://hastie.su.domains/ISLP/ISLP_website.pdf\n",
            "Resolving hastie.su.domains (hastie.su.domains)... 159.89.149.97\n",
            "Connecting to hastie.su.domains (hastie.su.domains)|159.89.149.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20053984 (19M) [application/pdf]\n",
            "Saving to: ‘/hastie_pdfs/ISLP_website.pdf’\n",
            "\n",
            "/hastie_pdfs/ISLP_w 100%[===================>]  19.12M  61.6MB/s    in 0.3s    \n",
            "\n",
            "2023-09-15 00:07:13 (61.6 MB/s) - ‘/hastie_pdfs/ISLP_website.pdf’ saved [20053984/20053984]\n",
            "\n",
            "--2023-09-15 00:07:13--  https://hastie.su.domains/Papers/ESLII.pdf\n",
            "Resolving hastie.su.domains (hastie.su.domains)... 159.89.149.97\n",
            "Connecting to hastie.su.domains (hastie.su.domains)|159.89.149.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21644344 (21M) [application/pdf]\n",
            "Saving to: ‘/hastie_pdfs/ESLII.pdf’\n",
            "\n",
            "/hastie_pdfs/ESLII. 100%[===================>]  20.64M  70.3MB/s    in 0.3s    \n",
            "\n",
            "2023-09-15 00:07:13 (70.3 MB/s) - ‘/hastie_pdfs/ESLII.pdf’ saved [21644344/21644344]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.0 Process PDF Files & Store in Chroma DB Vector Store"
      ],
      "metadata": {
        "id": "GA8hBdXxPuhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Documents for RAG"
      ],
      "metadata": {
        "id": "qV4TrBxWoh8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the drive - Do this only if GDrive is not mounted\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oeOSE73ATqC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you get Files from Hastie's Website - Use this Code\n",
        "# Note: This Takes about 3 mins\n",
        "loader = DirectoryLoader('/hastie_pdfs/', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
        "\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "2rQLeIh8phDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # For Files Stored in Google Drive Folder - Do the following\n",
        "# # Note: Loading from GDrive takes about 3 mins\n",
        "# loader = DirectoryLoader('/content/drive/MyDrive/hastie_pdfs/',\n",
        "#                          glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
        "\n",
        "# documents = loader.load()"
      ],
      "metadata": {
        "id": "jCyXdVqpPtJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Should get about 1377 pages if all goes well\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhxwZogHQpuK",
        "outputId": "d40a7381-0259-40e7-85b6-375ed1c68127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1377"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LLaMA-2 LLM Context is 4096 tokens so split document into chunks\n",
        "# Chunks are 1000 tokens with 200 token overlap\n",
        "# Should get 4439 chunks if all goes well\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE,\n",
        "                                               chunk_overlap=CHUNK_OVERLAP)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OSvYq3wP_2I",
        "outputId": "8f0f9428-c416-4a39-b826-b9c9314f50ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4439"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Sample Chunk from Book\n",
        "texts[20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM7dwLW9RDLj",
        "outputId": "06fa8b09-37b1-4576-ac38-640ba84ce810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='7.9 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\\n8 Tree-Based Methods 331\\n8.1 The Basics of Decision Trees . . . . . . . . . . . . . . . . . 331\\n8.1.1 Regression Trees . . . . . . . . . . . . . . . . . . . 331\\n8.1.2 Classification Trees . . . . . . . . . . . . . . . . . . 337\\n8.1.3 Trees Versus Linear Models . . . . . . . . . . . . . 341\\n8.1.4 Advantages and Disadvantages of Trees . . . . . . . 341\\n8.2 Bagging, Random Forests, Boosting, and Bayesian Additive\\nRegression Trees . . . . . . . . . . . . . . . . . . . . . . . . 343\\n8.2.1 Bagging . . . . . . . . . . . . . . . . . . . . . . . . 343\\n8.2.2 Random Forests . . . . . . . . . . . . . . . . . . . . 346\\n8.2.3 Boosting . . . . . . . . . . . . . . . . . . . . . . . . 347\\n8.2.4 Bayesian Additive Regression Trees . . . . . . . . . 350\\n8.2.5 Summary of Tree Ensemble Methods . . . . . . . . 353\\n8.3 Lab: Tree-Based Methods . . . . . . . . . . . . . . . . . . . 354', metadata={'source': '/hastie_pdfs/ISLP_website.pdf', 'page': 7})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Retriever Embeddings - HF BGE Embeddings\n",
        "BGE Embeddings are at the top of the leader board on Hugging Face (https://huggingface.co/spaces/mteb/leaderboard)."
      ],
      "metadata": {
        "id": "nSsXv9z8VqmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BGE Embedding Model for Retrieval. Embedding Size is 768.\n",
        "model_name = \"BAAI/bge-base-en\"\n",
        "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
        "\n",
        "model_embedding = HuggingFaceBgeEmbeddings(\n",
        "                    model_name=model_name,\n",
        "                    model_kwargs={'device': 'cuda'},\n",
        "                    encode_kwargs=encode_kwargs\n",
        "                  )"
      ],
      "metadata": {
        "id": "8VSSEV6XVvmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Vector DB Store Using Chroma DB\n"
      ],
      "metadata": {
        "id": "Tkp9EJvfWHp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Embed and store the texts\n",
        "# Supplying a persist_directory will store the embeddings on disk\n",
        "# Creating Vector Store takes ~ 2 mins\n",
        "\n",
        "persist_directory = 'db'\n",
        "\n",
        "## Here is the nmew embeddings being used\n",
        "embedding = model_embedding\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=texts,\n",
        "                                 embedding=embedding,\n",
        "                                 persist_directory=persist_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRYQe8t_WLc2",
        "outputId": "39f86ecb-4aab-4e9b-8c3d-c66b26ab70ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 1s, sys: 968 ms, total: 2min 1s\n",
            "Wall time: 2min 9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Returns the Top-k chunks from vectordb. Set to 2 to check.\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "JPuOi9poWZPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Retrieval From Chroma DB\n",
        "\n",
        "Both Approach 1 - Using Query and Approach 2 - Using Query Embedding should yield the same results.\n",
        "\n",
        "Embeddings are created using BGE Embeddings."
      ],
      "metadata": {
        "id": "VPxRX-HFk7Zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Approach 1: Use Query to do Similarity Search\n",
        "query = \"What is Linear Regression?\"\n",
        "docs = vectordb.similarity_search(query)\n",
        "print(docs[0].page_content)\n",
        "print(\"\\n\")\n",
        "print(docs[0].metadata)"
      ],
      "metadata": {
        "id": "zoZ6Fk6gk60L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9621abc-f695-4d10-ac3d-3a4efaa3f0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Linear Regression\n",
            "This chapter is about linear regression , a very simple approach for super-\n",
            "vised learning. In particular, linear regression is a useful tool for predicting\n",
            "a quantitative response. It has been around for a long time and is the topic\n",
            "of innumerable textbooks. Though it may seem somewhat dull compared to\n",
            "some of the more modern statistical learning approaches described in later\n",
            "chapters of this book, linear regression is still a useful and widely used sta-\n",
            "tistical learning method. Moreover, it serves as a good jumping-off point for\n",
            "newer approaches: as we will see in later chapters, many fancy statistical\n",
            "learning approaches can be seen as generalizations or extensions of linear\n",
            "regression. Consequently, the importance of having a good understanding\n",
            "of linear regression before studying more complex learning methods cannot\n",
            "be overstated. In this chapter, we review some of the key ideas underlying\n",
            "\n",
            "\n",
            "{'page': 77, 'source': '/hastie_pdfs/ISLP_website.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[1].page_content)\n",
        "print(\"\\n\")\n",
        "print(docs[1].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbPMr74G84MX",
        "outputId": "066f1182-185d-40b6-89c8-fab043cad7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Linear Regression\n",
            "This chapter is about linear regression , a very simple approach for super-\n",
            "vised learning. In particular, linear regression is a useful tool for predicting\n",
            "a quantitative response. It has been around for a long time and is the topic\n",
            "of innumerable textbooks. Though it may seem somewhat dull compared to\n",
            "some of the more modern statistical learning approaches described in later\n",
            "chapters of this book, linear regression is still a useful and widely used sta-\n",
            "tistical learning method. Moreover, it serves as a good jumping-off point for\n",
            "newer approaches: as we will see in later chapters, many fancy statistical\n",
            "learning approaches can be seen as generalizations or extensions of linear\n",
            "regression. Consequently, the importance of having a good understanding\n",
            "of linear regression before studying more complex learning methods cannot\n",
            "be overstated. In this chapter, we review some of the key ideas underlying\n",
            "\n",
            "\n",
            "{'page': 77, 'source': '/hastie_pdfs/ISLP_website.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Approach 2: Use Embedding Vector to do Similarity Search\n",
        "embedding_vector = embedding.embed_query(query)\n",
        "docs = vectordb.similarity_search_by_vector(embedding_vector)\n",
        "print(docs[0].page_content)\n",
        "print(\"\\n\")\n",
        "print(docs[0].metadata)\n"
      ],
      "metadata": {
        "id": "yjS212kklSMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e71236-e5b5-4bfa-d029-bb81cff01627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Linear Regression\n",
            "This chapter is about linear regression , a very simple approach for super-\n",
            "vised learning. In particular, linear regression is a useful tool for predicting\n",
            "a quantitative response. It has been around for a long time and is the topic\n",
            "of innumerable textbooks. Though it may seem somewhat dull compared to\n",
            "some of the more modern statistical learning approaches described in later\n",
            "chapters of this book, linear regression is still a useful and widely used sta-\n",
            "tistical learning method. Moreover, it serves as a good jumping-off point for\n",
            "newer approaches: as we will see in later chapters, many fancy statistical\n",
            "learning approaches can be seen as generalizations or extensions of linear\n",
            "regression. Consequently, the importance of having a good understanding\n",
            "of linear regression before studying more complex learning methods cannot\n",
            "be overstated. In this chapter, we review some of the key ideas underlying\n",
            "\n",
            "\n",
            "{'page': 77, 'source': '/hastie_pdfs/ISLP_website.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[1].page_content)\n",
        "print(\"\\n\")\n",
        "print(docs[1].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwN54n0-9X5q",
        "outputId": "80de5558-a4ff-4fde-d834-b5fb03c98bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Linear Regression\n",
            "This chapter is about linear regression , a very simple approach for super-\n",
            "vised learning. In particular, linear regression is a useful tool for predicting\n",
            "a quantitative response. It has been around for a long time and is the topic\n",
            "of innumerable textbooks. Though it may seem somewhat dull compared to\n",
            "some of the more modern statistical learning approaches described in later\n",
            "chapters of this book, linear regression is still a useful and widely used sta-\n",
            "tistical learning method. Moreover, it serves as a good jumping-off point for\n",
            "newer approaches: as we will see in later chapters, many fancy statistical\n",
            "learning approaches can be seen as generalizations or extensions of linear\n",
            "regression. Consequently, the importance of having a good understanding\n",
            "of linear regression before studying more complex learning methods cannot\n",
            "be overstated. In this chapter, we review some of the key ideas underlying\n",
            "\n",
            "\n",
            "{'page': 77, 'source': '/hastie_pdfs/ISLP_website.pdf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "X9S7ybZ0yKu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0 Setup LLM\n",
        "We are using LLaMA2 which is near the top of the leader board for Open LLM Models (https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard).\n",
        "\n",
        "LLaMA2 comes in 3 flavors - 7B, 13B, 70B. The base 7B model (assuming 4 Bytes or 32bits for each of the 7B weights) needs 28GB of RAM to load so we use a 4-bit Quantized Version of the model which should take 3.5GB and should be loadable using the free tier of Colab. Model used is:\n",
        "\n",
        "LLaMA2 7B GPTQ - The Bloke's Model which is a GPTQ quantized version of original LLaMA2 model. All weights are compressed to 4-bit and activations are stored in 16-bit bfloats. Model Card can be found here https://huggingface.co/TheBloke/Llama-2-7b-Chat-GPTQ."
      ],
      "metadata": {
        "id": "FZ15pQt7HVrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"TheBloke/Llama-2-7b-Chat-GPTQ\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "YcGou78wL19Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    # temperature=0.7,\n",
        "    # top_p=0.95,\n",
        "    repetition_penalty=1.15\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "hAHvueZ6HjCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check LLM"
      ],
      "metadata": {
        "id": "PjflYixgF5Zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What is Linear Regression?\n",
        "\n",
        "LLM knows what Linear Regression from its training data and gives a reasonable answer."
      ],
      "metadata": {
        "id": "t7MF7ltOxs2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is Linear Regression?\"\n",
        "prompt_template=f'''[INST] <<SYS>>\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "<</SYS>>\n",
        "{prompt}[/INST]\n",
        "\n",
        "'''\n",
        "\n",
        "print(\"\\n\\n*** Generate:\")\n",
        "\n",
        "print(pipe(prompt_template)[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQOzerjgE1kP",
        "outputId": "55a9a49b-092b-4e06-960b-b09a702c18a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "*** Generate:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] <<SYS>>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
            "<</SYS>>\n",
            "What is Linear Regression?[/INST]\n",
            "\n",
            "Linear regression is a statistical method used to model the relationship between two continuous variables: the independent variable (also called the predictor or explanatory variable) and the dependent variable (also called the outcome or response variable). The goal of linear regression is to create a linear equation that best predicts the value of the dependent variable based on the values of the independent variable(s).\n",
            "In simple terms, linear regression is a way to analyze how changes in one variable (the independent variable) affect another variable (the dependent variable). It helps to identify the strength and direction of the relationship between these two variables.\n",
            "For example, if you want to know how the price of a house affects its value, you can use linear regression to find out the exact line of best fit through the data points. This will give you an idea of how much the value of the house changes for every dollar change in the price.\n",
            "Linear regression is widely used in various fields such as finance, economics, marketing, and social sciences, among others. It is a powerful tool for making predictions, identifying trends, and understanding relationships between different variables.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What are trees?\n",
        "\n",
        "LLM does not have the context to know we are talking about ML trees rather than CS trees or trees in general.\n",
        "\n",
        "This results in the LLM Hallucinating or giving the wrong answer for our ML context.\n",
        "\n",
        "Since the LLM does not know we are talking about ML trees and not trees in general. This can be fixed either by giving the LLM the chat history or better yet improving the prompt as we see next."
      ],
      "metadata": {
        "id": "9XioPDouxZTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What are Trees?\"\n",
        "prompt_template=f'''[INST] <<SYS>>\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "<</SYS>>\n",
        "{prompt}[/INST]\n",
        "\n",
        "'''\n",
        "\n",
        "print(\"\\n\\n*** Generate:\")\n",
        "\n",
        "print(pipe(prompt_template)[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUOMaxATwzJg",
        "outputId": "f4cff3ef-8c3f-4c0f-cc85-75fa3f981519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "*** Generate:\n",
            "[INST] <<SYS>>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
            "<</SYS>>\n",
            "What are Trees?[/INST]\n",
            "\n",
            "Trees are living organisms that belong to the plant kingdom and are characterized by their ability to photosynthesize, grow from a single point (called a trunk), and have branches and roots that support their structure. They play a crucial role in the Earth's ecosystem by providing oxygen, food, shelter, and habitat for countless species of animals, insects, and microorganisms.\n",
            "There are over 60,000 known tree species worldwide, ranging in size from tiny shrubs to towering giants like the coast redwood (Sequoia sempervirens) and the Australian mountain ash (Eucalyptus regnans). Trees can be found in almost every corner of the globe, from the driest deserts to the wettest rainforests, and at elevations spanning from sea level to well above the snowline.\n",
            "Some of the key functions of trees include:\n",
            "1. Photosynthesis: Trees produce their own food through photosynthesis, using sunlight, water, and carbon dioxide to create glucose and oxygen. This process helps to purify the air we breathe and provides energy for the entire food chain.\n",
            "2. Oxygen production: Through photosynthesis, trees produce oxygen as a byproduct, which is essential for most life on Earth.\n",
            "3. Carbon sequestration: Trees absorb carbon dioxide from the atmosphere during photosynthesis, storing it in their biomass and soil. This helps to reduce the amount of greenhouse gases in the atmosphere, slowing down climate change.\n",
            "4. Soil formation: Tree roots help to aerate and improve soil quality, making it easier for other plants to grow.\n",
            "5. Wildlife habitats: Trees provide food, shelter, and nesting sites for countless species of birds, mammals, insects, and microorganisms.\n",
            "6. Climate regulation: Trees help to moderate local climates by providing shade, cooling the air through evapotranspiration, and blocking winds.\n",
            "7. Water cycle: Trees play a critical role in the global water cycle, influencing precipitation patterns, groundwater recharge, and streamflow.\n",
            "8. Noise reduction: Trees can act as a natural sound barrier, reducing noise pollution and creating a more peaceful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What are Decision Trees?\n",
        "We get a really great response once the context is clear."
      ],
      "metadata": {
        "id": "qBntwghI_czC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What are Decision Trees?\"\n",
        "prompt_template=f'''[INST] <<SYS>>\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "<</SYS>>\n",
        "{prompt}[/INST]\n",
        "\n",
        "'''\n",
        "\n",
        "print(\"\\n\\n*** Generate:\")\n",
        "\n",
        "print(pipe(prompt_template)[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-EZNV2w_ig4",
        "outputId": "4cc1a152-2cad-40fd-e51a-75cb50c62924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "*** Generate:\n",
            "[INST] <<SYS>>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
            "<</SYS>>\n",
            "What are Decision Trees?[/INST]\n",
            "\n",
            "Decision trees are a popular machine learning algorithm used for both classification and regression tasks. They work by recursively partitioning the data into smaller subsets based on the values of the input features. Each internal node in the tree represents a feature selection and the leaf nodes represent the predicted class or value. The process of building a decision tree involves selecting the best split at each node until the desired accuracy is reached.\n",
            "Decision trees have several advantages over other machine learning algorithms:\n",
            "1. Easy to interpret: Decision trees are easy to understand and interpret because they represent the logical reasoning behind the predictions.\n",
            "2. Handling missing values: Decision trees can handle missing values in the dataset, which can be a common problem in many machine learning tasks.\n",
            "3. Non-linear relationships: Decision trees can capture non-linear relationships between the features and target variable.\n",
            "4. High accuracy: Decision trees can achieve high accuracy compared to other machine learning algorithms when dealing with small datasets.\n",
            "5. Fast training time: Decision trees are relatively fast to train compared to other machine learning algorithms, making them suitable for large datasets.\n",
            "6. Robustness to outliers: Decision trees are robust to outliers in the dataset, meaning they can handle noisy data effectively.\n",
            "7. Ability to handle categorical variables: Decision trees can handle categorical variables directly without requiring any additional preprocessing steps.\n",
            "8. Interaction effects: Decision trees can capture interaction effects between features, which can lead to better predictions than using individual features alone.\n",
            "9. Model interpretation: Decision trees provide an interpretable model of the relationship between the features and target variable, allowing for insightful analysis of the data.\n",
            "However, there are also some disadvantages to consider:\n",
            "1. Overfitting: Decision trees can suffer from overfitting, especially when dealing with complex datasets. This means the model may perform well on the training set but poorly on new, unseen data.\n",
            "2. Computational complexity: Building decision trees can become computationally expensive when dealing with very large datasets.\n",
            "3. Limited flexibility: Once a decision tree has been built, it cannot be easily modified or updated.\n",
            "4. Noisy solutions: Decision trees can produce noisy solutions if the splitting criteria are not carefully chosen.\n",
            "5. Lack of control: Decision trees do not provide direct control over the complexity of the model, leading to potential overfitting issues.\n",
            "In summary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What are Boosted Trees?\n",
        "\n",
        "Providing a bit more context to the LLM returns a great result on Boosted trees also."
      ],
      "metadata": {
        "id": "wpr6xpjFx3dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What are Boosted Trees?\"\n",
        "prompt_template=f'''[INST] <<SYS>>\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "<</SYS>>\n",
        "{prompt}[/INST]\n",
        "\n",
        "'''\n",
        "\n",
        "print(\"\\n\\n*** Generate:\")\n",
        "\n",
        "print(pipe(prompt_template)[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2zNqOmXxCrp",
        "outputId": "f07ddde9-5617-4373-e44f-0952d95de048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "*** Generate:\n",
            "[INST] <<SYS>>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
            "<</SYS>>\n",
            "What are Boosted Trees?[/INST]\n",
            "\n",
            "Thank you for asking! Boosted trees are a type of machine learning algorithm used in natural language processing (NLP) tasks, particularly in text classification and sentiment analysis. In this context, \"boosted\" refers to the use of multiple weak models combined to create a stronger predictive model.\n",
            "The basic idea behind boosted trees is to train multiple decision trees on the same dataset, each with a different subset of features. The final prediction is made by combining the predictions of these individual trees using a weighted average. This approach can improve the accuracy and robustness of the model compared to using a single decision tree.\n",
            "Boosted trees have several advantages over traditional machine learning algorithms:\n",
            "1. Handling missing values: Missing values are common in many NLP datasets, but boosted trees can handle them more effectively than other algorithms.\n",
            "2. Dealing with imbalanced data: Many NLP datasets contain class imbalance issues, where one class has significantly more instances than others. Boosted trees can handle such situations better than other algorithms.\n",
            "3. Robustness to outliers: Boosted trees are less sensitive to outliers in the dataset, which can affect the performance of other algorithms.\n",
            "4. Ability to handle complex relationships: Boosted trees can capture complex relationships between features and classes, leading to improved accuracy.\n",
            "5. Interpretable results: Unlike some other machine learning algorithms, boosted trees provide interpretable results, allowing you to understand how the model arrived at its predictions.\n",
            "However, it's important to note that boosted trees may not always be the best choice for every NLP task. It's essential to evaluate different algorithms and choose the one that works best for your specific problem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup RAG Chain\n",
        "\n",
        "RAG Chain = LLM + Retriever + Query Prompt"
      ],
      "metadata": {
        "id": "Sd4whR8UGbhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "rnYD5Fh9IAnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retriever,\n",
        "                                  return_source_documents=True)"
      ],
      "metadata": {
        "id": "Om801LeKHoml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi"
      ],
      "metadata": {
        "id": "Ar190A9B6YDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check RAG Chain"
      ],
      "metadata": {
        "id": "9EXKUDhSH6H3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What about Linear Regression?\n",
        "\n",
        "Gives Reasonable Response about Linear Regression."
      ],
      "metadata": {
        "id": "oM0F-wsjyKd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Linear Regression?\"\n",
        "llm_response = qa_chain(query)\n",
        "llm_response['result'].split('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1bD6WOQHuFs",
        "outputId": "b5a796a4-81e2-4b27-eff8-d6de266dfb0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Linear regression is a type of regression analysis where the relationship between the independent variables and dependent variable is assumed to be linear.']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What about Trees?\n",
        "\n",
        "With RAG LLM does not hallucinate. It decides to not give an answer since it is not sure whether this is a decision tree (which is what we were thinking) or a boosted tree."
      ],
      "metadata": {
        "id": "WOrYaF8YyUp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are Trees?\"\n",
        "llm_response = qa_chain(query)\n",
        "llm_response['result'].split('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqteIxA9yYBt",
        "outputId": "fca9cd72-26f4-4f55-9718-bd6fb09afb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" I don't know the answer to this question as I am not familiar with the specific algorithm being discussed in the passage.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What about Boosted Trees?\n",
        "\n",
        "Gives short response for boosted trees that is not incorrect but the answer lacks depth. We will try and improve on this with better prompting next."
      ],
      "metadata": {
        "id": "bljC3kihyb79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are Boosted Trees?\"\n",
        "llm_response = qa_chain(query)\n",
        "llm_response['result'].split('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjPXVwwZybAj",
        "outputId": "eb1a6120-da12-4a3f-9228-71ada4dbca12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Boosted trees are a machine learning technique used to improve the accuracy of regression models. They work by combining multiple weak models to create a strong predictive model. In contrast to traditional regression techniques, which rely solely on a single model, boosted trees leverage the collective power of many weak models to produce more accurate predictions.']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG With Better Prompting"
      ],
      "metadata": {
        "id": "-mgsVbcp5aMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Default LLaMA-2 prompt style\n",
        "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
        "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
        "\n",
        "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
        "\n",
        "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT ):\n",
        "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
        "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
        "    return prompt_template"
      ],
      "metadata": {
        "id": "7iuFneKL5hed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys_prompt = \"\"\"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\n",
        "\n",
        "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \"\"\"\n",
        "\n",
        "instruction = \"\"\"CONTEXT:/n/n {context}/n\n",
        "\n",
        "Question: {question}\"\"\"\n",
        "get_prompt(instruction, sys_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "InXsTIRd5nRe",
        "outputId": "de84b503-475c-4432-9fe0-c77611415fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[INST]<<SYS>>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible using the context text provided. Your answers should only answer the question once and not have any text after the answer is done.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. \\n<</SYS>>\\n\\nCONTEXT:/n/n {context}/n\\n\\nQuestion: {question}[/INST]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = get_prompt(instruction, sys_prompt)\n",
        "\n",
        "llama_prompt = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Ko92oIix5rQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_type_kwargs = {\"prompt\": llama_prompt}"
      ],
      "metadata": {
        "id": "cjpJsTH-5rak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "IGXHrLpD5rjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                       chain_type=\"stuff\",\n",
        "                                       retriever=retriever,\n",
        "                                       chain_type_kwargs=chain_type_kwargs,\n",
        "                                       return_source_documents=True)"
      ],
      "metadata": {
        "id": "X9nfmM9955QM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cite sources\n",
        "def wrap_text_preserve_newlines(text, width=110):\n",
        "    # Split the input text into lines based on newline characters\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Wrap each line individually\n",
        "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
        "\n",
        "    # Join the wrapped lines back together using newline characters\n",
        "    wrapped_text = '\\n'.join(wrapped_lines)\n",
        "\n",
        "    return wrapped_text\n",
        "\n",
        "def process_llm_response(llm_response):\n",
        "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
        "    print('\\n\\nSources:')\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "QYa-C7Kv5-nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use Prompted RAG to Answer Some ML Questions\n",
        "\n",
        "RAG with better prompting gives us good responses. It figures out we are talking about decision trees. It also provides the source chunks we used to provide the answer which makes it easier to verify the response."
      ],
      "metadata": {
        "id": "UfwWVz88IBb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1\n",
        "query = \"What is Linear Regression?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irD0EgH55-tT",
        "outputId": "f19a3a6a-1060-4cfe-cc94-02abd08ac1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Linear regression is a statistical technique used to establish a linear relationship between a dependent\n",
            "variable (target variable) and one or more independent variables (predictor variables). It is a simple and\n",
            "widely used approach for supervised learning, which means the algorithm tries to predict the value of the\n",
            "target variable based on the input values of the predictor variables. The goal of linear regression is to\n",
            "create a linear equation that best fits the observed data, allowing predictions to be made on new\n",
            "observations.\n",
            "\n",
            "\n",
            "Sources:\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ESLII.pdf\n",
            "/hastie_pdfs/ESLII.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2\n",
        "query = \"What are Trees?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZMR5cAvz9sn",
        "outputId": "c5e4abd2-9bb2-49bd-8f55-7a15854fa8ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Trees are a type of machine learning algorithm used for classification and regression tasks. They consist of\n",
            "a series of splits or decisions made about the features of the data, with each split resulting in a smaller\n",
            "subset of the data. The final prediction is made by evaluating the features of the remaining observations in\n",
            "the dataset. Trees are particularly useful when dealing with complex datasets or high-dimensional feature\n",
            "spaces, as they can handle both linear and nonlinear relationships between the features and the target\n",
            "variable.\n",
            "\n",
            "\n",
            "Sources:\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ESLII.pdf\n",
            "/hastie_pdfs/ESLII.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3\n",
        "query = \"What are Boosted Trees?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6nLY8wh5-0n",
        "outputId": "53589634-6312-4a47-d51a-df9d3dba4f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Boosted trees refer to the process of combining multiple decision trees to create a more accurate prediction\n",
            "model. In the context of boosting, each decision tree is trained on the residuals of the previous tree,\n",
            "resulting in a sequence of trees that collectively improve the accuracy of the model. The final output of the\n",
            "boosting algorithm is a weighted sum of the predictions made by each individual tree, with larger weights\n",
            "indicating greater importance in the overall prediction.\n",
            "\n",
            "\n",
            "Sources:\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 4\n",
        "query = \"What is Random Forest?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkgnjLot6xIT",
        "outputId": "575c2fbf-3e55-4ed7-f719-2be1f20c54bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  A Random Forest is a machine learning algorithm that involves building multiple decision trees and combining\n",
            "their predictions to make a final prediction. Each decision tree is built by randomly sampling the training\n",
            "data and creating a subset of features for each tree. The Random Forest algorithm reduces overfitting by\n",
            "averaging the predictions of multiple trees and using a majority vote to make the final prediction.\n",
            "\n",
            "\n",
            "Sources:\n",
            "/hastie_pdfs/ESLII.pdf\n",
            "/hastie_pdfs/ESLII.pdf\n",
            "/hastie_pdfs/ESLII.pdf\n",
            "/hastie_pdfs/ESLII.pdf\n",
            "/hastie_pdfs/ESLII.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 5\n",
        "query = \"What are the Assumptions of Linear Regression?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GQ_QM64625q",
        "outputId": "7f81340e-5c48-49a6-9caa-598cb87d3e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  According to the given context, the assumptions of linear regression are:\n",
            "1. Additivity: The relationship between the predictors and response is additive, meaning that the association\n",
            "between a predictor and the response does not depend on the values of the other predictors.\n",
            "2. Linearity: The change in the response associated with a one-unit change in the predictor is constant,\n",
            "regardless of the value of the predictor.\n",
            "\n",
            "\n",
            "Sources:\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 6\n",
        "query = \"How does one correct for False Positives in Multiple Hypotheses testing?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMGpY1EK69DP",
        "outputId": "f8d74782-8bb8-4948-d1d9-af06e4332526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  To correct for false positives in multiple hypotheses testing, one can use multiple testing correction\n",
            "procedures such as Holm's procedure or Bonferroni's procedure. These procedures adjust the significance level\n",
            "based on the number of tests performed, reducing the risk of Type I errors. Additionally, more powerful\n",
            "procedures like the Šidák correction or the Holm-Bonferroni method can be used in special cases where higher\n",
            "power is desired while maintaining a controlled Family Wide Error Rate (FWER).\n",
            "\n",
            "\n",
            "Sources:\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n",
            "/hastie_pdfs/ISLP_website.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "Key takeaways are:\n",
        "\n",
        "1. Even small quantized Open Source LLMs such as the LLaMA-7B-GPTQ model are really good at QA.\n",
        "\n",
        "2. Inference with our model is fast even on a T4 GPU.\n",
        "\n",
        "3. Benefits of RAG include:\n",
        " * Reducing \"hallucinations\" by providing better context.\n",
        " * Increasing trust by providing source of response (White-boxing LLMs).\n",
        "\n",
        "4. RAG + Prompting gives the best responses to our ML questions.\n",
        "\n",
        "\n",
        "Additional Comments:\n",
        "- **VectorDB** - Can be used to do semantic search (based on user query intent rather than text matching) to return the revelant chunks of text. In our example on Linear Regression the ISLP text contains a chapter on linear regression so the Top-2 results or text chunks are from this chapter of the book.\n",
        "\n",
        "- **LLM** - Can answer questions related to ML but sometimes it \"hallucinates\". For example when asked about trees it responds about trees in general rather than decision trees which is what we intended.\n",
        "\n",
        "- **RAG** - Retrieves Top-5 chunks from Vector store (context) and provides it to the LLM in addition to the query. This improves the LLM results for the ML questions by providing additional context and also reduces LLM \"hallucinations\". For example asking RAG about trees results in LLM not giving a response since it does not know if we meant a \"decision\" tree or \"boosted\" tree.\n",
        "\n",
        "- **RAG + Prompting** - Adding better prompting to the RAG chain gives good responses for all our ML questions.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J-3cAK8Fa3zG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UxEOLEB4VNIk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}